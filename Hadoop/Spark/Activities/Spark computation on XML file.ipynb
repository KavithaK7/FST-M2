{
  "notebook_cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession",
        "",
        "# Initialize Spark session",
        "spark = SparkSession.builder \\",
        "    .appName('XML Processing') \\",
        "    .getOrCreate()"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading XML data using spark-xml",
        "df = spark.read.format('com.databricks.spark.xml') \\",
        "    .options(rowTag='yourRowTag') \\",
        "    .load('C:\\Users\\kavi\\FSTM2\\Spark\\dataFile.xml')"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the DataFrame schema",
        "df.printSchema()",
        "",
        "# Displaying the first few rows of the DataFrame",
        "df.show(5)"
      ],
      "outputs": [
        "root",
        " |-- yourRowTag: struct (nullable = true)",
        " |    |-- ...", 
        "+------------+",
        "| yourRowTag |", 
        "+------------+",
        "|   ...      |",
        "|   ...      |",
        "|   ...      |",
        "+------------+"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform further operations as needed",
        "# Example: df.filter(df['someColumn'] > 10).show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop Spark session (when done)",
        "spark.stop()"
      ],
      "outputs": []
    }
  ]
}
